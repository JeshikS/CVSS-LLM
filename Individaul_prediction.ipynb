{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reward based learning on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import unicodedata\n",
    "import itertools\n",
    "import logging\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from typing import KeysView\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import os\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nvd_data():\n",
    "    r = requests.get('https://nvd.nist.gov/vuln/data-feeds#JSON_FEED')\n",
    "    for filename in re.findall(\"nvdcve-1.1-[0-9]*\\.json\\.zip\",r.text):\n",
    "        print(filename)\n",
    "        r_file = requests.get(\"https://nvd.nist.gov/feeds/json/cve/1.1/\" + filename, stream=True)\n",
    "        filePath = \"zipFile\"\n",
    "        if not os.path.exists(filePath):\n",
    "            os.makedirs(filePath)\n",
    "        with open(\"zipFile/\" + filename, 'wb') as f:\n",
    "            for chunk in r_file:\n",
    "                f.write(chunk)\n",
    "get_nvd_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_data():\n",
    "    files = [f for f in listdir(\"zipFile/\") if isfile(join(\"zipFile/\", f))]\n",
    "    files.sort()\n",
    "    for file in files:\n",
    "        print(\"Opening: \" + file)\n",
    "        archive = zipfile.ZipFile(join(\"zipFile/\", file), 'r')\n",
    "        filePath = \"jsonFile\"\n",
    "        if not os.path.exists(filePath):\n",
    "            os.makedirs(filePath)\n",
    "        with archive as f:\n",
    "            f.extractall('jsonFile')\n",
    "unzip_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nvd_dict(year):\n",
    "    filename = join(\"jsonFile/nvdcve-1.1-\" + str(year) + \".json\")\n",
    "    #print(\"Opening: \" + filename)\n",
    "    with open(filename, encoding=\"utf8\") as json_file:\n",
    "        cve_dict = json.load(json_file)\n",
    "    return(cve_dict)\n",
    "\n",
    "def generate_CVSSV3csv_for_training():\n",
    "    list = listdir(\"jsonFile/\")\n",
    "    number_files = len(list)\n",
    "    print(number_files)\n",
    "    for year in range(2020,2025):\n",
    "        year_in_string = str(year)\n",
    "        cve_dict = create_nvd_dict(year)\n",
    "        fileName = 'NVD_'+ year_in_string + '_CVSSV3_train.csv'\n",
    "        with open('trainCVSSV3/' + fileName, 'w', newline='') as f_output:\n",
    "            csv_output = csv.writer(f_output)\n",
    "            csv_output.writerow(['CVE_ID', 'PublishTime','ModifyTime','Report','CVSSV3','AttackVector','AttackComplexity','PrivilegesRequired',\n",
    "                             'UserInteraction','Scope','ConfidentialityImpact','IntegrityImpact','AvailabilityImpact'])\n",
    "            for item in cve_dict['CVE_Items']:\n",
    "                cve_id = item['cve']['CVE_data_meta']['ID']\n",
    "                report = item['cve']['description']['description_data'][0]['value']\n",
    "                publish = item['publishedDate']\n",
    "                modify = item['lastModifiedDate']\n",
    "                if not report.find(\"**REJECT**\"):\n",
    "                    continue\n",
    "                if 'baseMetricV3' not in item['impact']:\n",
    "                    continue\n",
    "                elif 'baseMetricV3' in item['impact']:\n",
    "                    cvssv3_base_score = item['impact']['baseMetricV3']['cvssV3']['baseScore']\n",
    "                    attackVector = item['impact']['baseMetricV3']['cvssV3']['attackVector']\n",
    "                    attackComplexity = item['impact']['baseMetricV3']['cvssV3']['attackComplexity']\n",
    "                    privilegesRequired = item['impact']['baseMetricV3']['cvssV3']['privilegesRequired']\n",
    "                    userInteraction = item['impact']['baseMetricV3']['cvssV3']['userInteraction']\n",
    "                    scope = item['impact']['baseMetricV3']['cvssV3']['scope']\n",
    "                    confidentialityImpact = item['impact']['baseMetricV3']['cvssV3']['confidentialityImpact']\n",
    "                    integrityImpact = item['impact']['baseMetricV3']['cvssV3']['integrityImpact']\n",
    "                    availabilityImpact = item['impact']['baseMetricV3']['cvssV3']['availabilityImpact']\n",
    "\n",
    "                    csv_output.writerow([cve_id, publish, modify,report, cvssv3_base_score,\n",
    "                                 attackVector, attackComplexity, privilegesRequired, userInteraction,\n",
    "                                 scope, confidentialityImpact, integrityImpact, availabilityImpact])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_CVSSV3csv_for_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate training dataset using NVD reports from 2020 to 2025.\n",
    "def generate_CombinedFile():\n",
    "    list = listdir(\"trainCVSSV3/\")\n",
    "    number_files = len(list)-1\n",
    "    dict = []\n",
    "    dict_of_reports = {}\n",
    "    for year in range(2020,2025):\n",
    "        year_in_string = str(year)\n",
    "        file_name = 'NVD_'+ year_in_string + '_CVSSV3_train.csv'\n",
    "        dict_of_reports[year_in_string] = []\n",
    "        dict_of_reports[year_in_string] = pd.read_csv(\"trainCVSSV3/\" + file_name)\n",
    "        dict.append(dict_of_reports[year_in_string])\n",
    "    df = pd.concat(dict, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data frame generation for items in 'AttackVector'\n",
    "df = generate_CombinedFile()\n",
    "df.dropna(inplace=True)\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=42)\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize a list of descriptions\n",
    "#def tokenize_descriptions(text_list, tokenizer, max_length=512, padding=True):\n",
    "#    encodings = []\n",
    "#    for text in text_list:\n",
    "#        # Encode text to token IDs with padding and truncation\n",
    "#        encoded = tokenizer.encode_plus(text,max_length=max_length,padding='max_length' if padding else None,truncation=True,return_tensors='pt') # Change to your needed format (e.g., 'pt' for PyTorch tensors, 'tf' for TensorFlow, etc.)\n",
    "#    encodings.append(encoded['input_ids'].tolist()) # Extract input IDs\n",
    "#   return encodings\n",
    "\n",
    "def tokenize_descriptions(text_list, tokenizer, max_length=512, padding=True):\n",
    "# Encode the list of texts, processing them as a batch\n",
    "    return tokenizer(text_list,max_length=max_length,padding='max_length' if padding else False,truncation=True,return_tensors='pt')\n",
    "\n",
    "train_encodings = tokenize_descriptions(train_df['Report'].tolist(), tokenizer)\n",
    "val_encodings = tokenize_descriptions(val_test_df['Report'].tolist(), tokenizer)\n",
    "test_encodings = tokenize_descriptions(val_test_df['Report'].tolist(), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section is for Attack Vector item\n",
    "label_map = {'NETWORK': 0, 'ADJACENT_NETWORK': 1, 'LOCAL': 2, 'PHYSICAL': 3} \n",
    "train_labels = [label_map[label] for label in train_df['AttackVector']]\n",
    "val_labels = [label_map[label] for label in val_df['AttackVector']]\n",
    "test_labels = [label_map[label] for label in test_df['AttackVector']]\n",
    "\n",
    "\n",
    "class VulnerabilityDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = VulnerabilityDataset(train_encodings, train_labels)\n",
    "val_dataset = VulnerabilityDataset(val_encodings, val_labels)\n",
    "test_dataset = VulnerabilityDataset(test_encodings, test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine Tune model using Hugging Face\n",
    "#loading pretrained model \n",
    "model_name = \"bert-base-uncased\"\n",
    "# This is for the 4 labels in AttackVector\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "# Prepare training arguments\n",
    "training_args = TrainingArguments(\n",
    "output_dir='./results',\n",
    "# Choose the number of epochs, less epochs: Underfitting, too many: overfitting. \n",
    "# Check Evaluation metrics and adjust this. Computationally Intensive\n",
    "num_train_epochs=3, #set to 10 when given more computing power \n",
    "# Adjust batch size based on GPU memory. No Gpu now so keep this unaltered, change during deplayment phase\n",
    "per_device_train_batch_size=1, #set to 8 when given more computing power\n",
    "per_device_eval_batch_size=2, #set to 16 when given more computing power\n",
    "warmup_steps=500,\n",
    "weight_decay=0.01,\n",
    "logging_dir='./logs',\n",
    "logging_steps=10,\n",
    "evaluation_strategy=\"epoch\",\n",
    "save_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "model=model,\n",
    "args=training_args,\n",
    "train_dataset=train_dataset,\n",
    "eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
